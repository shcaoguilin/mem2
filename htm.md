[原文](https://numenta.org/resources/HTM_CorticalLearningAlgorithms.pdf)

## 1 分层临时记忆 概要
- 分层临时记忆 是 一个 机器学习技术, 它 的目标是 捕捉 新大脑皮层 的  结构和算法 属性.
- 新大脑皮层 是 智能 的 所在地, 在哺乳动物大脑中. 高 层 视觉,听觉,触觉,移动,语言,计划 都 是 由 新大脑皮层 执行的. 给定 这样 多 套 认知 功能, 你 或许 期待 新大脑皮层 实现 对等的 多套 神经 算法.  不是这样的情况. 新大脑皮层 显示 显著的 统一的 神经电路 模式 . 生物 证据 表明 新大脑皮层 实现了 一个 通用 算法 集  以 执行 多个 不同 智能 功能.
- 分层临时记忆 提供 一个 理论框架 来 理解 新大脑皮层 和 它的许多能力. 到目前为止 我们 已经 实现了 这个 理论 框架 的 一个 小 子集.  随着时间推移, 越来越多的 理论 将 被 实现. 今天 我们 相信 我们 已经 实现了 一个 足够的 子集, 关于 新大脑皮层 做了 什么, 以 具有 商用 和 科研 价值.
- 编程 分层临时记忆 不像 编程 传统 计算机. 今天的 计算机, 程序员 创建 特定的 程序 去 解决 特定 问题. 鲜明反差, 训练 分层临时记忆 通过 喂 给 感官数据流  . 分层临时记忆 的 能力 极大的 由 数据 决定.
- 分层临时记忆 可以 被 看作 一类 神经 网络. 按照 定义,  试图 去 建模 新大脑皮层 的 架构细节 的 系统 是 神经网络. 然而, 术语"神经网络" 不是 非常 有用 ,因为 它被 用到 各种 系统. 分层临时记忆 模型 的 神经元, 在一个hierarchy中, 被 组织 以 列、层、区. 按细节, 分层临时记忆 是 神经网络 的 一个 新形式.
- 如 名字 所 暗示 , 分层临时记忆 基本上 是 一个 基于 记忆 的 系统. 分层临时记忆 网络 用 许多 时变 数据 训练, 依赖于 存储的 模式 和 序列 的 大 集合. 数据 存储 和 访问 的方式 逻辑地 不同于 标准 模型 被 今天的 程序员 所用的.  经典 计算机 内存 是 一个 平的 组织 并且 没有 固有的 时间 概念. 一个 程序员 能 实现 任意 种类的 数据 组织 和 结构 在 平 计算机 内存 上. 他们 有 控制权 通过 如何、哪 信息 被 存储. 相反, 分层临时记忆 是 更 受约束的.  分层临时记忆 有 一个 hierarchy 组织 , 且 基于 固有的 时间. 信息 总是 存储 以 分布式的 样子.  分层临时记忆 的 用户 指定 hierarchy 尺寸, 系统 以 什么(数据) 训练, 但是 分层临时记忆 控制 信息  在哪、怎么 存储.
- 虽然 分层临时记忆 网络 显著的 不同于 经典 计算, (但) 我们 能 用 通用 目的 计算机 (去) 建模 他们 , 只要 我们 合并 关键 功能: 分层、时间分布表示、空间分布表示(稍后详叙). 我们 相信 假以时日, 专用 硬件 将 会 被 创建 去 生成 想要的 分层临时记忆 网络.
- 在 这个 文档 中, 我们 经常 表示 分层临时记忆 属性和原则 , 用 画的 例子 从 人类 视觉、触觉、听觉、语言和行为.  这些 例子 是 有用的, 因为 他们 是 直觉的 和 容易 抓住的. 但是, 它 是 重要的，心里 明白 分层临时记忆 能力 是 通用的。 他们 恰好 容易 换成 非人类 感官 输入 流，比如 雷达、红外线、 或  纯 信息 输入 流 像 金融 市场 数据、天气 数据、网页流量模式、文本。 分层临时记忆 是 学习并预测 机器 , 能 应用 到 多 种 问题。

### - 分层临时记忆 原理

- 在 这 段，我们 覆盖 分层临时记忆 核心 原理 的 一部分: 为什么 hierarchy 组织 是 重要的 ，如何 让 分层临时记忆 区 结构 化， 为什么 数据 被 存储为 稀疏 分布 表示，为什么 基于时间 信息 是 至少(要有)的.

#### - 分层
- 分层临时记忆 网络 包含 以 层次 组织 的 区.  在 分层临时记忆 中,  区 是 主 单位、预测, 在 下一 段　　 (区) 将 被 详细 讨论 . 典型地，每个 分层临时记忆 区 表示 在 hierarchy 中 的 一个 级别 . 当 你 向 上 hierarchy 走, 总 会 收敛,  在 一个 子 区 中 的 多个 元素 收敛 到 一个 父区 中 的 一个 元素. 然而，由于 反馈 连接，信息 也 发散 当你 向 下 hierarchy 走。（一个 区 和 一个 级别 几乎 是 同义词。 当 叙述 一个 区 的 内部 功能 时，我们 用 词 区；然而 当 特定地 提及 在 某个 hierarchy 内的 某个 区 的 某个 角色时，   我们 用 词 级别   ）
- 组合 多个 分层临时记忆 网络 是 可以的。  这种 结构 有 意义， 如果 你 有 数据 从 多个 源 或 传感器. 例如， 一个 网络 是 处理 听觉 信息 ，另一个 网络 是 处理 视觉 信息。 每个 单独 网络 是 收敛的, 而且 分离 的 分支 只 收敛  到 顶.
- hierarchy 组织 的 好处 是 效率. 它 显著地 降低了 训练 时间 和 内存 用量，因为 在 hierarchy 中  的 每个 级别 学到的 模式 被 重用， 当 在 更高 级 以 新奇的 方式 组合.  作为 例子， 让 我们 考虑 视觉.  在 hierarchy 的 最低 级， 你的 大脑 存储 关于    比如 可视域 边、角         微小 段 的 信息 。 一个 边 是  世界上 许多 物体 的 基础 组建 。   这些  低 级  模式 被  重组合  在 中级  进  更 复杂 组建  像 曲线、质地。  一条 弧 可以 是 耳朵 的 边， 操纵 轮 的 顶端 或者 咖啡 杯 的 边框.   这些 中级  模式 进一步  组合 到 表示 高 级  目标 特征， 比如 头、车、房子。 为了 学习 新 高 级 目标 ， 你 不 需要 重学 它的 组建。
- 另一个 例子 ，考虑 当 你 学 一个 新 字， 你 不必 重学 字母、音节、音素。
- 在 一个 hierarchy 中 共用  表示  也 导致 期待 的 行为 的 泛化.  当 你 看 一个 新 动物， 如果 你 看到 一个 嘴巴、牙齿， 你会 预测 这个动物 用 它的 牙齿 吃，它 可能 咬 你。  hierarchy 启用 了 一个 新 目标 在 世界 上 去 继承 它的 子组件 的 已知 属性 。
- 在 一个 分层临时记忆 hierarchy 的  一个 单 级 能 学 到 多少？或者 换个 方式， 在 hierarchy 中 多少 级 是 必要的？ 在 分配 多少 内存 给 每 级 和 需要 多少 级 之间 需要 平衡。  进一步地， 分层临时记忆 自动 学习 最 可能的 表示 在 每 级     给定  输入 统计  和 资源 分配 量。  如果 你 分配 更多 内存 给 一 级 ，  此 级  将 形成  更大 更复杂的  表示 ， 它 依次 意味着  更少的 必要 hierarchy 级 。  如果 你 分配 更少 内存， 一 级 将 形成 更小 更简单 的 表示 ， 它 依次  意味着 更多的 必要 hierarchy 级 。
- 到 这 点，我们 正 叙述 困难 问题， 比如 视觉 推理 （推理 是 类似的 和 模式 识别）。  但是 许多 有价值的 问题 是 更简单 比 视觉， 一个 但 分层临时记忆 区 可能 满足.  例如， 我们 应用 一个 分层临时记忆 去  预测 ， 一个 人 浏览 一个 网站 ，接下来 会 点击 哪里。  这个 问题 涉及 喂 分层临时记忆 网络 以 网页 点击 数据。  在 这个 问题 中， 少有 或 没有 spatial hierarchy， 解 几乎 (只) 需要 发现 temporal 统计， 比如 靠 识别 典型 用户 模式 来 预测 该用户 将 点击 哪里。 在 分层临时记忆 (中) 这个 temporal 学习 算法 对 这类 问题 很 理想。
- 总结下， hierarchies 降低 训练 时间，降低 内存 用量，导致 一种 形式 的  泛化。 但是，用 一个 单 分层临时记忆 区  (可以) 解 许多 简单 预测 问题 。
#### - 区
- 记号 区，在 一个 hierarchy 中 用 导线 连接的，来自 生物学。新大脑皮层 是 一个 巨大 的  组织 簿片，大约 2毫米 厚。 生物学家 分 新大脑皮层 成 不同 区域 或者 区 ， 主要 基于 该区 怎么 连到 其他 区。有些 区 直接 接收 输入 从 感官 ，    另一些 区 接收  输入,只 在 它(该输入) 通过了 若干 其他 区 后。 区到区 的 连接性 定义了 hierarchy.
- 全部 新大脑皮层 区 看着 类似，在 他们的 细节上。他们 变化 ，以 尺寸 ,以 他们 在 hierarchy 中的 哪， 除此之外 他们 是 类似的。 如果 你 取 一块 薄片,穿透 一个 新大脑皮层 区 的 2毫米 厚度，  你 会 看到 6 层， 5层 细胞,1层 非细胞(有 一些 例外,但 这是 一般 规则(规律))。 在 一个 新大脑皮层 的 每 层  有 许多 内部连接 细胞,以 列 排列。  分层临时 区域 也 是 片装 组装，片 是 高度 内连 的 细胞， 细胞 排列 在 列 中。 新大脑皮层 中的 层3  是 神经元 主 前馈 层 之一。  一个 分层临时记忆 区 粗略 等于 ，新大脑皮层 一个 区 中 的 层3 中的 神经元们。
- 图1.3 : 一个 分层临时记忆 区 的 一个 段. 分层临时记忆 的 区们 由 许多 细胞 组成。  这些 细胞 在 列 中 以 二维 形式 组织. 这个 图 显示 一个 分层临时记忆 区 的 一个 小 段， 每 列 4个 细胞。 在这个区中，每 列 连接 到 输入 子集，每 细胞 连接 到 其他 细胞(连接没有显示). 注意 这个 分层临时记忆 区 ， 包含 它的 圆柱形(列) 结构 ， 等同于 在 一个 新大脑皮层 区 中 的 一 层 神经元.
- 虽然 一个 分层临时记忆 区 是 仅仅 等同于 新大脑皮层 中的 一份 区，它(该区) 能做 推理 和 预测 ,在 复杂 数据流 上,因此 (区 是) 有用的 在 许多 问题 (上).    
#### - 稀疏分布表示
- 虽然 新大脑皮层 (中的)  神经元 是 高度 内连的 ，抑制 神经元 保证了 仅仅 一 小 百分比 神经元 是 激活的 ,在 (任)一个 时刻. 因此，大脑 中 的 信息 总是 被 表示, 用 一个 巨大 人口(数目) 神经元 中的 一 小 百分比 的 激活 神经元。 这种 编码 叫做 稀疏分布表示。  稀疏 意思是 仅仅 一 小 百分比 的 神经元 是 激活的 , 在 (任)一个 时刻.  分布 意思是 , 为了 表示 某个 事物, 需要 激活 多个 神经元. 一个 单 激活 神经元 表达 某个 意思, 但 它 必须 被 解释,在  表达 整个含义(该事物) 的 全体 神经元   的 上下文 (中).
- 分层临时记忆 区(们) 也 用 稀疏分布表示。  事实上， 在 一个 分层临时记忆 区 内 的 记忆 原理(结构)(机制) 依赖于 使用 稀疏分布表示，否则 (区) 不工作。 给 一个 分层临时记忆 区 的 输入 总是 一个 分布表示，但 它 可能 不是 稀疏的，所以 一个 分布临时记忆 区 要做 的 第一件 事 是 转化 它的 输入 到(为)(成) 一个 稀疏分布表示.
- 例如，一个 区 可以 接收 2万 bit 的 输入。  输入 bit 中 1 、0 的 百分比 随 时间 显著 变化.  一时刻 可能 有 5千个  bit 1, 另一 时刻 可能 有 9千个  bit 1。  该 分册临时记忆 可以 转化 这个 输入 到 一个 1万 bit 的 内部 表示 , 它(该内部表示) 一次  有 2% 即 200个 bit 是 激活 的 ， 不论 这个 输入 中 有 多少 bit 1. 因为 这个 分层临时记忆 区 的 输入 随 时间 变化， 内部 表示 也(随时间) 变化，但是 1万 bit 中 总是 只有 200 bit 是 激活的。
- 看起来,这个 过程 产生了 信息 的 巨大 丢失,因为 可能的 输入 模式 数量 远多于 在 该 区 中  可能的 表示 数量。  然而， 这 两个 数 都是 巨 大的。一个 区 看到的 该 实际 输入(们)  是 全体 可能 输入 中的 很小的 小部分。 稍后 我们 会 叙述 一个 区 如何 从 它的 输入 创建 一个 稀疏表示. 信息 的 理论上 的 损失 不会 有 实用 效应.
- 图1.4 一个 分层临时记忆 区 正显示 稀疏 分布的 细胞 激活
- 稀疏分布表示 有 若干 吸引人的 属性,而且 被 集成 到 分层临时记忆 的 操作 . 后面 还会 再 讲到.
- #### - 时间角色
- 时间 扮演 一个 决定性的 校色, 在 学习、推理、预测 中.
- 让 我们 从 推理 开始。  不 使用 时间，我们 几乎 不能 从 我们的 触觉、听觉 推理 (任何东西). 比如 ， 如果 你 被 蒙上 眼睛, (然后) 有人 方 一个 苹果 在 你 手上， 在 你 操纵 它(苹果) 仅仅 1秒 后，你 (就能) 知道 它 是 什么。当 你 在 苹果 上 移动 你的 手指 ，虽然 触觉 信息 不断 变化，目标 自身 -- 苹果，如同 你的 高层 感知 "苹果", 保持不变。但是，如果 一个 苹果 放在 你 张开的 手掌 中, 并且 不 允许 你 移动 你的 手 或 手指 ， 你 会 很难 分清 它 是 一个 苹果 还是 一个 柠檬。
- 对于 听觉 也是 一样 成立。 一个 静态的 声音 表达 极少的 意思。一个 字 ,比如 苹果,或 某人 咬 一个 苹果 的 咯吱 声音，只能 被 识别 出来， 从 音谱的 一打或几百个 急流、随时间的 连续的 变化 。
- 相比之下，视觉，是个 混合 情况。 不像 触觉、听觉，人类 能 识别 图像,当 他们(图像) 瞬间  闪亮(出现) 在 他们(人类) 面前,  (出现的) 太快 以至于 没给 眼睛 机会 去 移动(译者:没给眼睛移动的机会,因此视觉能力没有利用时变输入). 因此，视觉 推理 不 总是 需要 时变 输入。  但是，在 正常 视觉 期间，我们 不断 移动 我们的 眼睛、头、身体，并且 世界上 的 目标(物体) 也 在 我们的 周围 移动。 我们的 推理 能力,基于 快速 画面 曝光, 是 一个 特 例, 由 视觉 统计 属性 和 多年 训练  制造的. 视觉、听觉、触觉 的 通用 情形 是 基于  需要 时变 输入 的 推理(译者认为 作者这里有点故意往自己的东西上套的嫌疑 忽略了解释不了的事实).
- 刚刚 覆盖了 推理的 通用 情况， 特殊 情况: 静态 图像 的 视觉 推理 ， 现在 让 我们 看下 学习。  为了 去 学习，在 训练期间 , 所有 分层临时记忆 系统 必须 面对 时变 输入 .  即使 在 视觉 上, 静态 推理 有时 是 可能的，我们 必须 看 物体(们) 的 变化 图像 , 去 学习 一个 物体 看起 像 什么。 例如，想象 一只 狗 正 朝你 跑 来。 在 时间上 的 每一个 瞬间 , 这只狗 导致了 一个 激活 模式,在 你 眼睛 的 视网膜 上。你 知觉到 这些 模式 是 一个 相同的 狗 的 不同 view，但是 数学地(数学上看) 这些模式 是 完全地 不相似。大脑 学到 这些 不同的 模式 意味着 相同的 东西 ，靠 按 序列地 观察 他们 (的方式). 时间 是 监督者， 教 你 哪些 空间 模式 放在 一起。
- 注意 对于 感官 输入 仅仅 去 改变 是 不够的 。 你 学 会 辨别 狗(们) ,  靠 看 很多  不同 品种 的 狗 实例 ， 而 不是 只有 一 单个 狗 的 一 单个 view。分层临时记忆 算法 的 工作 是 去 学 临时 序列 , 从 一个 输入 数据 流， 比如 构建 一个 模型,哪些 模式 跟在 哪些 其他 模式 后面。  这个 工作 是 困难的,因为 它 可能 不知道 序列 的 开始 、 结束，在 相同时刻 可能 有 覆盖 序列 出现，   学习 必须 连续地 发生， 并且 学习 必须 在 噪音 存在 (的情形下) 发生 .
- 学习、识别 序列 是 形成 预测 的 基础。 一旦 一个 分层临时记忆 学到 什么 模式(们) 很 可能 跟随 其他 模式(们), 给定 当前 输入、直接 过去 输入(们),它(分层临时记忆) 能 预测 很可能的 接下来的 模式(们).  稍后 会 覆盖 到 预测 的 更多 细节 。
- 我们 现在 将 转向 分层临时记忆 的 四个 基本 功能：学习、推理、预测、行为。 每一个 分层临时记忆 区 执行 前 三个 功能：学习、推理、预测。 然而，行为 是 不同的。从 生物学,我们 知道 新大脑皮层 的 大多数 区(们) 有 一个 角色,创建 行为,  但是 对于 许多 有趣的 应用,我们 不相信 它(行为) 是 必需品。 因此 在 我们 当前 分层临时记忆 实现 中,我们 没 包含 行为. 这里 我们 提及 它(行为),是 出于 完整性.
### - 学习
- 一个 分层临时记忆 区 了解 它的 世界,靠 在 感官 数据 中 找 模式、then 序列。(该)区 不知道 输入 代表 什么；它 工作,以 一个 纯粹的 统计 领域。 ==它(该区) 寻找 输入 bit(们) 的  组合, 经常 出现 在 一起 的,(该组合) 我们 称之为  空间 模式(们)。 然后，它(该区) 寻找 这些 空间 模式(们) 怎么 出现,按 时刻 序列, (该时刻序列) 我们 称之为 临时 模式(们) 或 序列(们)。==
- 如果 到 (该)区 的 输入 表示 在 一个 建筑物 (中的) 环境 传感器(们)，(该)区 可能 会 发现  温度、湿度 的  特定 组合(们),在 (该)建筑物 北边 经常 出现,而且 在 (该)建筑物 南边 出现 不同的 组合。然后,随着 每天 流逝, 它(该区) 可能 学到 这些 组合(们) 的 序列(们) .
- 如果 到 一个 区 的输入 表示 在 一个 店 内 的  跟  购买(们) 相关的 信息， 分层临时记忆 的 (该)区 可能 发现,在周末 特定 类型(们) 的 物品(们) 被 购买，或者 当 天气 冷 了,在晚上,特定 价格 范围(们) 被 偏爱。然后 它(该区) 学到 不同的 个人 跟随 相似的 序列 模式(们),在 他们 的 购买 中。
- 一个 单 分层临时记忆 区 有 受限的 学习 能力。 一个 区 自动地 调整 它(该区) 学 什么,基于 它(该区) 有 多少 内存,它(该区) 收到的 输入 的 复杂度。被 一个 区 学到的 该 空间 模式(们) 会 必然地 变的 更简单,如果 分配 给 一个 区 的 内存 被 降低. 或者 学到的 空间 模式(们) 可以 变得 更 复杂,如果 分配的 内存 被 增加了。 在 一个 区, 如果 学到的 空间 模式(们) 是 简单的,那么 区(们) 的 (一个) hierarchy 可能 需要 区 理解 复杂 图像(们)。 我们 看到 这个 特性,在 人类 视觉 系统 中,新大脑皮层 区 接收 输入 从 视网膜,(区) 学到 可视空间的 小 部分(们) 的 空间 模式(们)。只有 在 若干个 hierarchy级 后,做 空间 模式(们) 组合 并 表示 可视化 空间 的  大多数 或 全部。
- 像 一个 生物学 系统 一样， 在 一个 分层临时记忆 区 中 的  学习 算法 有 在线 学习 能力，例如 他们(区们) 连续地 从 每个 新输入 学习 。  这 不是 必要的,对于 学习 阶段 和 推理 阶段 分离，虽然 在 额外的 学习 后,推理 改善了. 当 在 输入 中的 模式(们) 改变，分层临时记忆 区 也 会 逐渐地 改变。
- 在 初始 训练 后，一个 分层临时记忆 能 连续 学习 ，或，在 训练 阶段 后 学习 可以 被 禁用。 另一个 选项 是 只 在 该hierarchy的 最低 级,关掉学习,但 在 更高 级 继续 学习。一旦  一个 分层例是记忆 已经 学到 它的 世界 的 基本 统计 结构，大多数 新 学习 出现 在 该hierarchy 的 更 上层 。 如果 一个 分层临时记忆 被 暴露 到 新 模式,之前 没 见过的 低级 结构，对 分层临时记忆,它 将 花 更久 去 学到 这些 新 模式。在 人类 中，我们 看到了 这特点。在 一个 你 已经 知道的  语言 中,学习 新 词(们) 是 相对 容易的。 然而，从 一个 不熟悉 的 发音 的 外语 中，如果 你 试图 学 新 词(们)，你 会 发现 这 非常 困难,因为 你 不 已经 知道 低级 发音。
- 简单地 发现 模式 是 一个 潜在 价值 能力。 在 市场 波动、灾难、气象、理解、制造商 投资收益,或 复杂系统 失效,如 电网， 理解 高 级  模式 是 有 价值的 。即便 如此，多数情况下, 学习 空间 、 临时 模式 是 推理、预测 的 先驱。
### - 推理
- 在 一个 分层临时记忆 已经 学会 这个 世界的 模式，它 能 在 新奇的 输入 上 执行 推理。 当 一个 分层临时记忆 收到 输入 ，它 将 匹配 先前 学到的 空间、时间 模式(们)。 成功地 匹配 新 输入 到 先前 存储的 序列(们) 是 推理、模式匹配 的 精要。
- 考虑 下 你 如何 识别 一个 曲子 的。听到 曲子 中的  第一个 音符,告诉你 很少。第二个 音符 显著地 缩小了 可能性,但 它 或许 仍然 不够。 通常 听 三、四 或 更多个 音符,你 你 会 识别 出 (该)曲子。在 一个 分层临时记忆 的 区 中 的  推理,是 类似的。 它 不断地 看 (一个) 输入 流,并匹配 他们 到 先前 学到的 序列(们)。一个 分层临时记忆 区 能 发现 匹配,从 序列(们) 的 开始,但 通常 它(开始处) 是 更 流动的(不定的)，类似 与,你 如何 能 识别 到 一个 从 任何地方 开始的 曲子。因为 分层临时记忆 区(们)
